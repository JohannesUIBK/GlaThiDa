{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_pyth(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"Calculate the distance between two points \"\"\"\n",
    "    return np.sqrt((lat2 - lat1)**2 + (lon2 - lon1)**2)\n",
    "\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between one point \n",
    "    on the earth and an array of points (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters\n",
    "    return c * r\n",
    "\n",
    "\n",
    "def p_dist(lon1, lat1, lon2, lat2, units=None):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two *CLOSE* points in meters using Pythagoras\n",
    "    \"\"\"\n",
    "    if units == 'm':\n",
    "        dist = dist_pyth(lon1, lat1, lon2, lat2)\n",
    "    elif units == 'deg':\n",
    "        dist = haversine(lon1, lat1, lon2, lat2)\n",
    "    else:\n",
    "        raise ValueError('Units must be meters (m) or degrees (deg).')\n",
    "        \n",
    "    return dist\n",
    "\n",
    "\n",
    "def p_thin(df, xcol='x', ycol='y', datacols='data', radius=10, method='nanmean', units=None):\n",
    "    \"\"\"\n",
    "    Thin a pandas point series based on distance of the points. The first point in the DataFrame is taken and all points \n",
    "    within the search distance are found and the given method is applied to the data columns. Used data are deleted from \n",
    "    the frame and the procedure is repeated. Data are written to the point which is closest to the half of the search\n",
    "    distance away from the initial point.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pseries: Series of points\n",
    "    xcol: name of column with x coordinates\n",
    "    ycol: name of columns with y coordinates\n",
    "    datacol: name of columns with data (list/string)\n",
    "    radius: search radius for point distance (meters)\n",
    "    method: calculation method (a numpy method). Default: 'nanmean'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A thinned dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert units!=None,'Units of x/y must be meters (m) or degrees (deg).'\n",
    "    \n",
    "    thinned = pd.DataFrame([],columns=df.columns.values)\n",
    "    \n",
    "    print(len(df))\n",
    "    ct=0\n",
    "    while len(df)>0:\n",
    "        df['DIST'] = p_dist(df[xcol].iloc[0], df[ycol].iloc[0], df[xcol], df[ycol], units=units)\n",
    "        df = df.sort_values('DIST')\n",
    "\n",
    "        subset = df[df.DIST <= radius]\n",
    "\n",
    "        if not subset.empty:\n",
    "            subset = subset.reset_index()\n",
    "            # find the point ID which is closest to half of the search distance \n",
    "            #(to this point the new data will be assigned)\n",
    "            assign_id = subset.ix[(subset.DIST-(radius/2.)).abs().argsort()[0]].name\n",
    "            \n",
    "            fill_dict = {}\n",
    "            fill_dict[xcol] = subset.loc[assign_id, xcol]\n",
    "            fill_dict[ycol] = subset.loc[assign_id, ycol]\n",
    "            for data in datacols:\n",
    "                try:\n",
    "                    fill_dict[data] = getattr(np,method)(subset[data].values)\n",
    "                except TypeError:\n",
    "                    fill_dict[data] = np.nan\n",
    "            thinned.loc[len(thinned)] = pd.Series(fill_dict)\n",
    "            ct+=1\n",
    "\n",
    "            if ct%100==0:\n",
    "                print(ct,len(df))\n",
    "                \n",
    "        # delete the used points from the data\n",
    "        df = df.drop(df[df.DIST <= radius].index.values)\n",
    "        \n",
    "    print(len(thinned))\n",
    "    return thinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = glob('C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\CH_Huss-Fischer\\\\GlaThiDa2.0_UFR\\\\results\\\\*_TTT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "thin_dict = {'tortin': 6,\n",
    "             'tsanfleuron': 6,\n",
    "    \n",
    "}\n",
    "\n",
    "date_dict = {'tortin':20130399,\n",
    "            'tsanfleuron':20100399\n",
    "}\n",
    "\"\"\"\n",
    "search_dist = 10  # forward search distance for thinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747\n",
      "95\n",
      "5007\n",
      "100 3709\n",
      "200 2254\n",
      "300 1014\n",
      "386\n",
      "2014\n",
      "100 934\n",
      "186\n",
      "2753\n",
      "100 1654\n",
      "200 557\n",
      "251\n",
      "2266\n",
      "100 1137\n",
      "200 62\n",
      "206\n",
      "995\n",
      "90\n",
      "1263\n",
      "90\n",
      "1356\n",
      "100 153\n",
      "116\n",
      "3238\n",
      "100 1908\n",
      "200 737\n",
      "267\n",
      "3250\n",
      "100 1984\n",
      "200 885\n",
      "278\n",
      "2754\n",
      "100 1660\n",
      "200 507\n",
      "237\n",
      "6227\n",
      "100 5043\n",
      "200 3906\n",
      "300 2763\n",
      "400 1708\n",
      "500 595\n",
      "555\n",
      "6299\n",
      "100 5716\n",
      "200 5269\n",
      "300 4945\n",
      "400 4394\n",
      "500 3998\n",
      "600 3481\n",
      "700 2933\n",
      "800 2335\n",
      "900 1136\n",
      "1000 507\n",
      "1064\n",
      "308\n",
      "100 128\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    fname = os.path.basename(file)\n",
    "    data = pd.read_excel(file)\n",
    "    punit = data['POLITICAL_UNIT'].values[0]\n",
    "    gname = data['GLACIER_NAME'].values[0]\n",
    "    sdate = data['SURVEY_DATE'].values[0]\n",
    "    \n",
    "    # old thinning\n",
    "    # data = data.groupby(data.index // thin_dict[fname.split('_')[0]]).mean()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        data = p_thin(data, xcol='POINT_LON', ycol='POINT_LAT', datacols=['ELEVATION', 'THICKNESS', 'THICKNESS_UNCERTAINTY'], \n",
    "                      radius=search_dist, method='nanmean', units='deg')\n",
    "    \n",
    "    data['ELEVATION'] = data['ELEVATION'].round()\n",
    "    data['THICKNESS'] = data['THICKNESS'].round()\n",
    "    data['POLITICAL_UNIT'] = punit\n",
    "    data['GLACIER_NAME'] = gname\n",
    "    data['POINT_ID'] = range(1,len(data)+1)\n",
    "    data['SURVEY_DATE'] = sdate\n",
    "    if not pd.isnull(data['REMARKS']).any():\n",
    "        data['REMARKS'] =  data['REMARKS'].astype(str) + 'Point data have been thinned (mean) within a search distance of %s m.' % search_dist\n",
    "    else:\n",
    "        data['REMARKS'] = 'Point data have been thinned (mean) within a search distance of %s m.' % search_dist\n",
    "    \n",
    "    \n",
    "    data = data[['GlaThiDa_ID' ,'POLITICAL_UNIT', 'GLACIER_NAME', 'SURVEY_DATE', 'POINT_ID',  'POINT_LAT',  'POINT_LON',  'ELEVATION', \n",
    "                 'THICKNESS', 'THICKNESS_UNCERTAINTY', 'DATA_FLAG', 'REMARKS']]\n",
    "    \n",
    "    data.to_excel(os.path.join(os.path.dirname(file),fname.split('.')[0]+'_thinned.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
