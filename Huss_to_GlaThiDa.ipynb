{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths_t = glob('C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\CH_Huss-Fischer\\\\GlaThiDa2.0_UFR\\\\results\\\\*_T.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# new GTD IDs\\nnew_ids= {}\\nbegin = 2091\\nct=0\\nfor path in paths_t:\\n    new_ids[os.path.split(path)[-1].split('.')[0]] = begin + ct\\n    ct+=1\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not needed, new IDs are already prescribed in \n",
    "\"\"\"\n",
    "# new GTD IDs\n",
    "new_ids= {}\n",
    "begin = 2091\n",
    "ct=0\n",
    "for path in paths_t:\n",
    "    new_ids[os.path.split(path)[-1].split('.')[0]] = begin + ct\n",
    "    ct+=1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlandman\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\jlandman\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "for path_t in paths_t:\n",
    "    t_dat = pd.read_csv(path_t, header=None, sep=': ')\n",
    "    tt_path = os.path.join(os.path.dirname(path_t),os.path.split(path_t)[1].split('.')[0]+'T.dat')\n",
    "    tt_dat = pd.read_csv(tt_path, header=None, sep=': ')\n",
    "    ttt_path = os.path.join(os.path.dirname(path_t),os.path.split(path_t)[1].split('.')[0]+'TT.dat')\n",
    "    ttt_dat = pd.read_csv(ttt_path, header=None, delim_whitespace=True)\n",
    "\n",
    "    excel = pd.DataFrame([], [0])\n",
    "    excel.loc[excel.index==0, 'GlaThiDa_ID'] = np.nan # has to be inserted manually in the Excel sheet, later on\n",
    "    excel.loc[excel.index==0, 'POLITICAL_UNIT'] = 'CH'\n",
    "    excel.loc[excel.index==0, 'GLACIER_NAME'] = t_dat[t_dat[0] == 'Glacier name'][1].iloc[0].upper().strip()\n",
    "    excel.loc[excel.index==0, 'SOURCE_ID'] = np.nan\n",
    "    excel.loc[excel.index==0, 'GLACIER_ID'] = np.nan\n",
    "    excel.loc[excel.index==0, 'LAT'] = float(t_dat[t_dat[0] == 'lat'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'LON'] = float(t_dat[t_dat[0] == 'lon'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'SURVEY_DATE'] = int(t_dat[t_dat[0] == 'Survey Date'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'DEM_DATE'] = int(t_dat[t_dat[0] == 'DEM Date'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'AREA'] = float(t_dat[t_dat[0] == 'Area'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'MEAN_SLOPE'] = float(t_dat[t_dat[0] == 'Mean slope'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'MEAN_THICKNESS'] = float(t_dat[t_dat[0] == 'Mean thickness'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'MEAN_THICKNESS_UNCERTAINTY'] = float(t_dat[t_dat[0] == 'Mean thickness uncertainty'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'MAXIMUM_THICKNESS'] = float(t_dat[t_dat[0] == 'Max thickness'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'MAX_THICKNESS_UNCERTAINTY'] = float(t_dat[t_dat[0] == 'Max thickness uncertainty'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'SURVEY_METHOD'] = t_dat[t_dat[0] == 'Method'][1].iloc[0].strip()\n",
    "    excel.loc[excel.index==0, 'SURVEY_METHOD_DETAILS'] = t_dat[t_dat[0] == 'Method details'][1].iloc[0].strip()\n",
    "    excel.loc[excel.index==0, 'NUMBER_OF_SURVEY_POINTS']= int(t_dat[t_dat[0] == 'Survey points'][1].iloc[0])\n",
    "    excel.loc[excel.index==0, 'NUMBER_OF_SURVEY_PROFILES'] = np.nan\n",
    "    excel.loc[excel.index==0, 'TOTAL_LENGTH_OF_SURVEY_PROFILES'] = np.nan\n",
    "    excel.loc[excel.index==0, 'INTERPOLATION_METHOD'] = ''\n",
    "    excel.loc[excel.index==0, 'INVESTIGATOR'] = t_dat[t_dat[0] == 'Investigator'][1].iloc[0].strip()\n",
    "    excel.loc[excel.index==0, 'SPONSORING_AGENCY'] = t_dat[t_dat[0] == 'Sponsor'][1].iloc[0].strip()\n",
    "    excel.loc[excel.index==0, 'REFERENCES'] = t_dat[t_dat[0] == 'Reference'][1].iloc[0].strip()\n",
    "    excel.loc[excel.index==0, 'DATA_FLAG'] = np.nan\n",
    "    excel.loc[excel.index==0, 'REMARKS'] = ''\n",
    "    \n",
    "    \n",
    "    \"\"\"excel_tt = pd.DataFrame([], range(len(tt_dat)))\n",
    "    for k, row in excel_tt.iterrows():\n",
    "        excel_tt.loc[excel_tt.index==k, 'GlaThiDa_ID'] = np.nan\n",
    "        excel_tt.loc[excel_tt.index==k, 'POLITICAL_UNIT'] = 'CH'\n",
    "        excel_tt.loc[excel_tt.index==k, 'GLACIER_NAME'] = t_dat[t_dat[0] == 'Glacier name'][1].iloc[0].upper()\n",
    "        excel_tt.loc[excel_tt.index==k, 'SURVEY_DATE'] = t_dat[t_dat[0] == 'Survey Date'][1].iloc[0]\n",
    "        excel_tt.loc[excel_tt.index==k, 'LOWER_BOUND'] = pd.Series([i.split(' - ')[0] for i in tt_dat[0].values])\n",
    "        excel_tt.loc[excel_tt.index==k, 'UPPER_BOUND'] = pd.Series([i.split('-')[1] for i in tt_dat[0].values])\n",
    "        excel_tt.loc[excel_tt.index==k, 'AREA'] = pd.Series([i.split(';')[0] for i in tt_dat[2].values])\n",
    "        excel_tt.loc[excel_tt.index==k, 'MEAN_SLOPE'] = np.nan\n",
    "        excel_tt.loc[excel_tt.index==k, 'MEAN_THICKNESS'] = pd.Series([i.split('; ')[0] for i in tt_dat[4].values])\n",
    "        excel_tt.loc[excel_tt.index==k, 'MEAN_THICKNESS_UNCERTAINTY'] = np.nan\n",
    "        excel_tt.loc[excel_tt.index==k, 'MAXIMUM_THICKNESS'] = tt_dat[5]\n",
    "        excel_tt.loc[excel_tt.index==k, 'MAXIMUM_THICKNESS_UNCERTAINTY'] = np.nan\n",
    "        excel_tt.loc[excel_tt.index==k, 'DATA_FLAG'] = np.nan\n",
    "        excel_tt.loc[excel_tt.index==k, 'REMARKS'] = ''\n",
    "    \n",
    "    \n",
    "    excel_ttt = pd.DataFrame([], range(len(ttt_dat)))\n",
    "    print(ttt_path, len(excel_ttt), excel_ttt)\n",
    "    for k, row in excel_ttt.iterrows():\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'GlaThiDa_ID'] = np.nan\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'POLITICAL_UNIT'] = 'CH'\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'GLACIER_NAME'] = t_dat[t_dat[0] == 'Glacier name'][1].iloc[0].upper()\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'SURVEY_DATE'] = t_dat[t_dat[0] == 'Survey Date'][1].iloc[0]\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'POINT_ID'] = ttt_dat[ttt_dat.index==k][0].iloc[0]\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'POINT_LAT'] = ttt_dat[ttt_dat.index==k][2].iloc[0]\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'POINT_LON'] = ttt_dat[ttt_dat.index==k][1].iloc[0]\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'ELEVATION'] = round(ttt_dat[ttt_dat.index==k][3].iloc[0])\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'THICKNESS'] = round(ttt_dat[ttt_dat.index==k][4].iloc[0],1)\n",
    "        \n",
    "        excel_ttt.loc[excel_ttt.index==k, 'THICKNESS_UNCERTAINTY'] = np.nan\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'DATA_FLAG'] = np.nan\n",
    "        excel_ttt.loc[excel_ttt.index==k, 'REMARKS'] = ''\"\"\"\n",
    "\n",
    "    excel.to_excel(path_t[:-4]+'.xlsx', index=False)\n",
    "    \"\"\"excel_tt.to_excel(tt_path[:-4]+'.xlsx', index=False)\n",
    "    excel_ttt.to_excel(ttt_path[:-4]+'.xlsx', index=False)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
