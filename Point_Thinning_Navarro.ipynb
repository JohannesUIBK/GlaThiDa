{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_pyth(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"Calculate the distance between two points \"\"\"\n",
    "    return np.sqrt((lat2 - lat1)**2 + (lon2 - lon1)**2)\n",
    "\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between one point \n",
    "    on the earth and an array of points (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in meters\n",
    "    return c * r\n",
    "\n",
    "\n",
    "def p_dist(lon1, lat1, lon2, lat2, units=None):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two *CLOSE* points in meters using Pythagoras\n",
    "    \"\"\"\n",
    "    if units == 'm':\n",
    "        dist = dist_pyth(lon1, lat1, lon2, lat2)\n",
    "    elif units == 'deg':\n",
    "        dist = haversine(lon1, lat1, lon2, lat2)\n",
    "    else:\n",
    "        raise ValueError('Units must be meters (m) or degrees (deg).')\n",
    "        \n",
    "    return dist\n",
    "\n",
    "\n",
    "def p_thin(df, xcol='x', ycol='y', datacols='data', radius=10, method='nanmean', units=None):\n",
    "    \"\"\"\n",
    "    Thin a pandas point series based on distance of the points. The first point in the DataFrame is taken and all points \n",
    "    within the search distance are found and the given method is applied to the data columns. Used data are deleted from \n",
    "    the frame and the procedure is repeated. Data are written to the point which is closest to the half of the search\n",
    "    distance away from the initial point.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pseries: Series of points\n",
    "    xcol: name of column with x coordinates\n",
    "    ycol: name of columns with y coordinates\n",
    "    datacol: name of columns with data (list/string)\n",
    "    radius: search radius for point distance (meters)\n",
    "    method: calculation method (a numpy method). Default: 'nanmean'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A thinned dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert units!=None,'Units of x/y must be meters (m) or degrees (deg).'\n",
    "    \n",
    "    thinned = pd.DataFrame([],columns=df.columns.values)\n",
    "    \n",
    "    print(len(df))\n",
    "    ct=0\n",
    "    while len(df)>0:\n",
    "        df['DIST'] = p_dist(df[xcol].iloc[0], df[ycol].iloc[0], df[xcol], df[ycol], units=units)\n",
    "        df = df.sort_values('DIST')\n",
    "\n",
    "        subset = df[df.DIST <= radius]\n",
    "\n",
    "        if not subset.empty:\n",
    "            subset = subset.reset_index()\n",
    "            # find the point ID which is closest to half of the search distance \n",
    "            #(to this point the new data will be assigned)\n",
    "            assign_id = subset.ix[(subset.DIST-(radius/2.)).abs().argsort()[0]].name\n",
    "            \n",
    "            fill_dict = {}\n",
    "            fill_dict[xcol] = subset.loc[assign_id, xcol]\n",
    "            fill_dict[ycol] = subset.loc[assign_id, ycol]\n",
    "            for data in datacols:\n",
    "                try:\n",
    "                    fill_dict[data] = getattr(np,method)(subset[data].values)\n",
    "                except TypeError:\n",
    "                    fill_dict[data] = np.nan\n",
    "            thinned.loc[len(thinned)] = pd.Series(fill_dict)\n",
    "            ct+=1\n",
    "\n",
    "            if ct%100==0:\n",
    "                print(ct,len(df))\n",
    "                \n",
    "        # delete the used points from the data\n",
    "        df = df.drop(df[df.DIST <= radius].index.values)\n",
    "        \n",
    "    print(len(thinned))\n",
    "    return thinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\SJ_AQ_Navarro\\\\final\\\\GlaThiDa_Navarro1_Johannes.xlsx', 'C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\SJ_AQ_Navarro\\\\final\\\\GlaThiDa_Navarro2_Johannes.xlsx']\n"
     ]
    }
   ],
   "source": [
    "files = glob('C:\\\\Users\\\\jlandman\\\\Desktop\\\\newData\\\\SJ_AQ_Navarro\\\\final\\\\*_Johannes.xlsx')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "thin_dict = {\"ELFENBEINBREEN\": 14,\n",
    "             \"SVEIGBREEN\": 4,\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "search_dist = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14624\n",
      "100 14377\n",
      "200 14156\n",
      "300 13952\n",
      "400 13733\n",
      "500 13512\n",
      "600 13302\n",
      "700 13098\n",
      "800 12883\n",
      "900 12665\n",
      "1000 12463\n",
      "1100 12233\n",
      "1200 12031\n",
      "1300 11827\n",
      "1400 11619\n",
      "1500 11396\n",
      "1600 11170\n",
      "1700 10909\n",
      "1800 10684\n",
      "1900 10482\n",
      "2000 10269\n",
      "2100 10066\n",
      "2200 9855\n",
      "2300 9635\n",
      "2400 9433\n",
      "2500 9230\n",
      "2600 9028\n",
      "2700 8828\n",
      "2800 8530\n",
      "2900 8257\n",
      "3000 8043\n",
      "3100 7838\n",
      "3200 7638\n",
      "3300 7429\n",
      "3400 7229\n",
      "3500 7014\n",
      "3600 6804\n",
      "3700 6603\n",
      "3800 6357\n",
      "3900 6152\n",
      "4000 5949\n",
      "4100 5747\n",
      "4200 5544\n",
      "4300 5347\n",
      "4400 5150\n",
      "4500 4948\n",
      "4600 4748\n",
      "4700 4545\n",
      "4800 4341\n",
      "4900 4127\n",
      "5000 3924\n",
      "5100 3718\n",
      "5200 3514\n",
      "5300 3311\n",
      "5400 3112\n",
      "5500 2890\n",
      "5600 2687\n",
      "5700 2465\n",
      "5800 2247\n",
      "5900 2038\n",
      "6000 1821\n",
      "6100 1612\n",
      "6200 1404\n",
      "6300 1200\n",
      "6400 995\n",
      "6500 787\n",
      "6600 575\n",
      "6700 287\n",
      "6800 71\n",
      "6835\n",
      "4241\n",
      "100 4064\n",
      "200 3893\n",
      "300 3711\n",
      "400 3531\n",
      "500 3335\n",
      "600 3174\n",
      "700 2984\n",
      "800 2824\n",
      "900 2652\n",
      "1000 2488\n",
      "1100 2330\n",
      "1200 2208\n",
      "1300 2032\n",
      "1400 1768\n",
      "1500 1453\n",
      "1600 1241\n",
      "1700 1036\n",
      "1800 845\n",
      "1900 665\n",
      "2000 475\n",
      "2100 277\n",
      "2200 81\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "data_new = pd.DataFrame([])\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_excel(file, sheetname='TTT - GL. THICKNESS POINT DATA')\n",
    "    for gid in np.unique(data.GlaThiDa_ID.values):\n",
    "        temp = data[data.GlaThiDa_ID==gid]\n",
    "\n",
    "        gname = temp[temp.GlaThiDa_ID == gid].GLACIER_NAME.values[0]\n",
    "        pol_u = temp[temp.GlaThiDa_ID == gid].POLITICAL_UNIT.values[0]\n",
    "        surv_date = temp[temp.GlaThiDa_ID == gid].SURVEY_DATE.values[0]\n",
    "        remarks = temp[temp.GlaThiDa_ID == gid].REMARKS.iloc[0]\n",
    "        if not pd.isnull(remarks).any():\n",
    "            remarks = remarks + ' Point data have been thinned (mean) within a search distance of %s m.' % search_dist\n",
    "        else:\n",
    "            remarks = 'Point data have been thinned (mean) within a search distance of %s m.' % search_dist\n",
    "        gtd_id = gid\n",
    "        \n",
    "        # old point thinning\n",
    "        # temp = temp.groupby(temp.index // thin_dict[gname]).mean() # average over every x values as specified above\n",
    "        temp = p_thin(temp, xcol='POINT_LON', ycol='POINT_LAT', datacols=['ELEVATION', 'THICKNESS', 'THICKNESS_UNCERTAINTY'], \n",
    "                      radius=search_dist, method='nanmean', units='deg')\n",
    "\n",
    "        temp['POLITICAL_UNIT'] = pol_u\n",
    "        temp['GLACIER_NAME'] = gname\n",
    "        temp['REMARKS'] = remarks\n",
    "        temp['DATA_FLAG'] = np.nan\n",
    "        temp['GlaThiDa_ID'] = gtd_id\n",
    "        temp['SURVEY_DATE'] = surv_date\n",
    "        temp['POINT_ID'] = range(1,len(temp)+1)\n",
    "\n",
    "        data_new = data_new.append(temp, ignore_index=True)\n",
    "\n",
    "data_new['THICKNESS_UNCERTAINTY'] = data_new['THICKNESS_UNCERTAINTY'].round()\n",
    "data_new['THICKNESS'] = data_new['THICKNESS'].round()\n",
    "data_new['ELEVATION'] = data_new['ELEVATION'].round()\n",
    "\n",
    "data_new = data_new[['GlaThiDa_ID','POLITICAL_UNIT', 'GLACIER_NAME', 'SURVEY_DATE', 'POINT_ID',  'POINT_LAT',  'POINT_LON', \n",
    "                     'ELEVATION', 'THICKNESS', 'THICKNESS_UNCERTAINTY', 'DATA_FLAG', 'REMARKS']]\n",
    "\n",
    "data_new = data_new.sort_values(by=['GlaThiDa_ID','POINT_ID'])\n",
    "data_new.to_excel(os.path.join(os.path.dirname(file),file.split('.')[0]+'_thinned.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
